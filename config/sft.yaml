# base model
pretrained_model_name_or_path: "google/gemma-2b" # REQUIRED

############################################ quantization ##########################################################
# quantization
load_in_4bit: true
bnb_4bit_quant_type: "nf4"
# bnb_4bit_compute_dtype": "bf16"

############################################ PEFTConfig ##########################################################
task_type: "CAUSAL_LM"
lora_r: 8
target_modules:
    [
        "q_proj",
        "o_proj",
        "k_proj",
        "v_proj",
        "gate_proj",
        "up_proj",
        "down_proj",
    ]
lora_alpha: 16
lora_dropout: 0.1

# dataset
# dataset: ["HuggingFaceH4/ultrachat_200k", "hfl/stem_zh_instruction"]
# dataset: "timdettmers/openassistant-guanaco"
dataset: "llamafactory/alpaca_gpt4_zh" # REQUIRED

############################################ SFTConfig ##########################################################
output_dir: "" # setted dynamicaly in utils.py, with pretrained_model_name_or_path + dataset + date
per_device_train_batch_size: 1
gradient_accumulation_steps: 16
warmup_steps: 2
max_steps: 10
learning_rate: 2.0e-4
fp16: true
optim: "paged_adamw_8bit"
max_seq_length: 512

# log
log_level: info
logging_first_step: true
logging_steps: 1

# save
save_strategy: steps # If "epoch" or "steps", saving will also be performed at the very end of training, always.
save_steps: 500
